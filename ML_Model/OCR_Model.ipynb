{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:53:57.166260Z",
     "iopub.status.busy": "2023-11-07T07:53:57.165995Z",
     "iopub.status.idle": "2023-11-07T07:54:11.739439Z",
     "shell.execute_reply": "2023-11-07T07:54:11.738452Z",
     "shell.execute_reply.started": "2023-11-07T07:53:57.166233Z"
    }
   },
   "outputs": [],
   "source": [
    "#need for kaggle online ipynb\n",
    "#! pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:11.741361Z",
     "iopub.status.busy": "2023-11-07T07:54:11.740938Z",
     "iopub.status.idle": "2023-11-07T07:54:15.820586Z",
     "shell.execute_reply": "2023-11-07T07:54:15.819781Z",
     "shell.execute_reply.started": "2023-11-07T07:54:11.741286Z"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1699300569130,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "ZE_3Upkh8S4Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import imutils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout, SpatialDropout2D, GlobalMaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:15.822313Z",
     "iopub.status.busy": "2023-11-07T07:54:15.821791Z",
     "iopub.status.idle": "2023-11-07T07:54:16.237934Z",
     "shell.execute_reply": "2023-11-07T07:54:16.236612Z",
     "shell.execute_reply.started": "2023-11-07T07:54:15.822283Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "0NBNVP5Z8S4U",
    "outputId": "b506d66e-c2bf-4c11-949e-1316bdc3be18"
   },
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# #make sure to use GPU\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:16.242111Z",
     "iopub.status.busy": "2023-11-07T07:54:16.241540Z",
     "iopub.status.idle": "2023-11-07T07:54:16.262871Z",
     "shell.execute_reply": "2023-11-07T07:54:16.261844Z",
     "shell.execute_reply.started": "2023-11-07T07:54:16.242069Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "EVsLn4-78S4U",
    "outputId": "0821be22-4f0b-40f1-a625-126b728b92fd"
   },
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:16.265133Z",
     "iopub.status.busy": "2023-11-07T07:54:16.264246Z",
     "iopub.status.idle": "2023-11-07T07:54:16.273723Z",
     "shell.execute_reply": "2023-11-07T07:54:16.272701Z",
     "shell.execute_reply.started": "2023-11-07T07:54:16.265093Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "M43xho-pFh64"
   },
   "outputs": [],
   "source": [
    "# for google colab - after you load your kaggle api token you can give it permissions on colab (if using colab)\n",
    "# !chmod 600 /content/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:16.275500Z",
     "iopub.status.busy": "2023-11-07T07:54:16.275121Z",
     "iopub.status.idle": "2023-11-07T07:54:16.283892Z",
     "shell.execute_reply": "2023-11-07T07:54:16.282938Z",
     "shell.execute_reply.started": "2023-11-07T07:54:16.275463Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "CItBsSbBE3tl"
   },
   "outputs": [],
   "source": [
    "# google colab \n",
    "# ! kaggle datasets download -d vaibhao/handwritten-characters\n",
    "# ! kaggle datasets download -d landlord/handwriting-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:16.296579Z",
     "iopub.status.busy": "2023-11-07T07:54:16.295651Z",
     "iopub.status.idle": "2023-11-07T07:54:16.305107Z",
     "shell.execute_reply": "2023-11-07T07:54:16.304138Z",
     "shell.execute_reply.started": "2023-11-07T07:54:16.296541Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "RHJGfwKAHLHt"
   },
   "outputs": [],
   "source": [
    "# import zipfile #unzipping the dataset (google colab)\n",
    "# zip_ref = zipfile.ZipFile('handwritten-characters.zip', 'r')\n",
    "# zip_ref.extractall('/content/datasets/handwritten-characters')\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:54:16.307249Z",
     "iopub.status.busy": "2023-11-07T07:54:16.306359Z",
     "iopub.status.idle": "2023-11-07T07:54:16.314738Z",
     "shell.execute_reply": "2023-11-07T07:54:16.313760Z",
     "shell.execute_reply.started": "2023-11-07T07:54:16.307203Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1699300569997,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "WSX8gEi-IS1L"
   },
   "outputs": [],
   "source": [
    "# import zipfile #unzipping the dataset (google colab)\n",
    "# zip_ref = zipfile.ZipFile('handwriting-recognition.zip', 'r')\n",
    "# zip_ref.extractall('/content/datasets/handwriting-recognition')\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team used following datasets (images): <br>\n",
    "In handwritten model (used in final version):\n",
    "- [Handwritten Characters] https://www.kaggle.com/datasets/vaibhao/handwritten-characters/ (used for training)\n",
    "- [Handwriting Recognition] https://www.kaggle.com/datasets/landlord/handwriting-recognition (used for testing)\n",
    "\n",
    "In second model (both were combined into one and split into training and testing sets):\n",
    "- [Printed Digits] https://www.kaggle.com/datasets/dhruvmomoman/printed-digits\n",
    "- [Camera-Taken Images of Printed English Alphabet] https://www.kaggle.com/datasets/naderabdalghani/camerataken-images-of-printed-english-alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for kaggle (online model):\n",
    "# dir = \"/kaggle/input/handwritten-characters/Train/\"\n",
    "\n",
    "dir = \"datasets/handwritten-characters/Train/\"\n",
    "val_dir = \"datasets/handwritten-characters/Validation/\"\n",
    "\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "img_size = 32\n",
    "limit_train_images = 4200\n",
    "limit_val_images = 1000\n",
    "\n",
    "non_chars = [\"#\",\"$\",\"&\",\"@\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "\n",
    "def get_data(dir, max_images, not_list, data_list):\n",
    "    for i in os.listdir(dir):\n",
    "        if i in not_list:\n",
    "            continue\n",
    "        count = 0\n",
    "        sub_directory = os.path.join(dir,i)\n",
    "        for j in os.listdir(sub_directory):\n",
    "            count+=1\n",
    "            if count > max_images: #limiting the number of images per label\n",
    "                break\n",
    "            img = cv2.imread(os.path.join(sub_directory,j),0)\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            data_list.append([img,i])\n",
    "\n",
    "\n",
    "get_data(dir, limit_train_images, non_chars, train_data)\n",
    "get_data(val_dir, limit_val_images, non_chars, val_data)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "for features,label in train_data:\n",
    "    train_X.append(features)\n",
    "    train_Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = []\n",
    "val_Y = []\n",
    "for features,label in val_data:\n",
    "    val_X.append(features)\n",
    "    val_Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data\n",
    "train_X = np.array(train_X)/255.0\n",
    "train_X = train_X.reshape(-1,32,32,1)\n",
    "train_Y = np.array(train_Y)\n",
    "\n",
    "val_X = np.array(val_X)/255.0\n",
    "val_X = val_X.reshape(-1,32,32,1)\n",
    "val_Y = np.array(val_Y)\n",
    "\n",
    "print(train_X.shape,val_X.shape)\n",
    "print(train_Y.shape,val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T08:17:36.312994Z",
     "iopub.status.busy": "2023-11-07T08:17:36.312615Z",
     "iopub.status.idle": "2023-11-07T08:17:36.849492Z",
     "shell.execute_reply": "2023-11-07T08:17:36.848706Z",
     "shell.execute_reply.started": "2023-11-07T08:17:36.312934Z"
    },
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1699300580232,
     "user": {
      "displayName": "Maksims Fokins",
      "userId": "06260264702503327285"
     },
     "user_tz": -60
    },
    "id": "zp26dsuS8S4X"
   },
   "outputs": [],
   "source": [
    "# Label binarization\n",
    "LB = LabelBinarizer()\n",
    "train_Y = LB.fit_transform(train_Y)\n",
    "val_Y = LB.fit_transform(val_Y)\n",
    "LB.classes_\n",
    "\n",
    "#save as the label file\n",
    "np.save('label_classes.npy', LB.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading random 1000 rows (texts) from csv for testing\n",
    "handwritten_test_data = pd.read_csv(\"datasets/handwriting-recognition/written_name_test_v2.csv\")\n",
    "handwritten_test_data = handwritten_test_data.sample(n=1000)\n",
    "\n",
    "# loading 1000 images from test dataset for loaded texts\n",
    "handwritten_dir = \"datasets/handwriting-recognition/test_v2/test/\"\n",
    "handwritten_test_data[\"image\"] = \"\"\n",
    "\n",
    "for index, row in handwritten_test_data.iterrows():\n",
    "    img = cv2.imread(os.path.join(handwritten_dir,row[\"FILENAME\"]),0)\n",
    "    handwritten_test_data.at[index,\"image\"] = img\n",
    "\n",
    "# preparing data\n",
    "handwritten_test_X = []\n",
    "handwritten_text_Y = []\n",
    "for index, row in handwritten_test_data.iterrows():\n",
    "    handwritten_test_X.append(row[\"FILENAME\"])\n",
    "    handwritten_text_Y.append(row[\"IDENTITY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN3HE9KC8S4Y"
   },
   "source": [
    "**Experiments with models and layers**\n",
    "- MaxPooling2D to use over AveragePooling2D as it is more robust to noise.\n",
    "- Dropout to reduce overfitting.\n",
    "- BatchNormalization to normalize the activations of the previous layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tf.keras.layers.Reshape((128, 1)), #these 3 layers are for the RNN and increase time taken to train by a lit 2min -> 25min per epoch on CPU\n",
    "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, dropout=0.25)), #\n",
    "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.25)), #\n",
    "    # tf.keras.layers.Flatten(),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "#maybe consider something like this for the RNN part of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), activation='gelu', padding='same', kernel_initializer='he_normal', input_shape=(img_size, img_size,1)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(SpatialDropout2D(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='gelu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(SpatialDropout2D(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), strides=(1, 1), activation='gelu', padding='same', kernel_initializer='he_normal'))\n",
    "model.add(SpatialDropout2D(0.4))\n",
    "model.add(GlobalMaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='gelu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='gelu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(25, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-07T08:17:40.728597Z",
     "iopub.status.busy": "2023-11-07T08:17:40.728307Z"
    },
    "id": "zGvloDZV8S4a",
    "outputId": "6c5ba9fc-557a-4571-99bd-bd0c94ea3674"
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 20, restore_best_weights=True)\n",
    "history = model.fit(train_X,train_Y, epochs=60, batch_size=32, validation_data = (val_X, val_Y),  verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T09:04:08.277266Z",
     "iopub.status.busy": "2023-11-07T09:04:08.276860Z",
     "iopub.status.idle": "2023-11-07T09:04:08.544928Z",
     "shell.execute_reply": "2023-11-07T09:04:08.543991Z",
     "shell.execute_reply.started": "2023-11-07T09:04:08.277233Z"
    },
    "id": "lyHR7L3E8S4a"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T09:04:14.433703Z",
     "iopub.status.busy": "2023-11-07T09:04:14.432998Z",
     "iopub.status.idle": "2023-11-07T09:04:14.709342Z",
     "shell.execute_reply": "2023-11-07T09:04:14.708474Z",
     "shell.execute_reply.started": "2023-11-07T09:04:14.433668Z"
    },
    "id": "hm-6uqhs8S4a"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(\"textReadModel(handwritten).keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model on recognition set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "    key=lambda b:b[1][i], reverse=reverse))\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letters(img):\n",
    "    letters = []\n",
    "    image = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n",
    "    dilated = cv2.dilate(thresh1, None, iterations=2)\n",
    "\n",
    "    cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) > 10:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        roi = gray[y:y + h, x:x + w]\n",
    "        thresh = cv2.threshold(roi, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        thresh = cv2.resize(thresh, (32, 32), interpolation = cv2.INTER_CUBIC)\n",
    "        thresh = thresh.astype(\"float32\") / 255.0\n",
    "        thresh = np.expand_dims(thresh, axis=-1)\n",
    "        thresh = thresh.reshape(1,32,32,1)\n",
    "        ypred = model.predict(thresh)\n",
    "        ypred = LB.inverse_transform(ypred)\n",
    "        [x] = ypred\n",
    "        letters.append(x)\n",
    "    return letters, image\n",
    "\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(letter):\n",
    "    word = \"\".join(letter)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter,image = get_letters(\"datasets/handwriting-recognition/train_v2/train/TRAIN_00023.jpg\")\n",
    "word = get_word(letter)\n",
    "print(word)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter,image = get_letters(\"datasets/handwriting-recognition/train_v2/train/TRAIN_00003.jpg\")\n",
    "word = get_word(letter)\n",
    "print(word)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter,image = get_letters(\"datasets/handwriting-recognition/train_v2/train/TRAIN_00030.jpg\")\n",
    "word = get_word(letter)\n",
    "print(word)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter,image = get_letters(\"datasets/handwriting-recognition/test_v2/test/TEST_0007.jpg\")\n",
    "word = get_word(letter)\n",
    "print(word)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading random 1000 rows from csv \n",
    "test_data = pd.read_csv(\"datasets/handwriting-recognition/written_name_test_v2.csv\")\n",
    "test_data = test_data.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction method for testing\n",
    "def predict_test(filename, label):\n",
    "    dir = \"datasets/handwriting-recognition/test_v2/test/\"\n",
    "    letter,image = get_letters(os.path.join(dir,filename))\n",
    "    word = get_word(letter)\n",
    "    print(\"predicted: \" + word)\n",
    "    print(\"actual: \" + label)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction test\n",
    "index = random.randint(0,999)\n",
    "filename = handwritten_test_X[index]\n",
    "label = handwritten_text_Y[index]\n",
    "predict_test(filename, label)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
