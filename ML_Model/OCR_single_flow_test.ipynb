{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Goal of this book is to combine text detection and image processing (+character segmentation) with OCR model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import keras_ocr\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = keras_ocr.detection.Detector()\n",
    "model = load_model(\"textReadModel(printed).keras\") # model trained on printed text\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = load_model(\"textReadModel(handwritten).keras\") # model trained on handwritten dataset\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label binarizer for digits and characters to allow inverse transform (to see the predicted text as a text)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit_transform([\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\n",
    "        \"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\n",
    "        \"V\",\"W\",\"X\",\"Y\",\"Z\",\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\n",
    "        \"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\n",
    "        \"z\"])\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognition and Post-Processing <br>\n",
    "The sort contours function is used to get the correct order of individual characters for correct output extraction. In this case for extracting a single word, a left to right sorting of individual characters is needed.\n",
    "The get letters function fetches the list of letters and get word function gets the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    reverse = False\n",
    "    i = 0\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "    key=lambda b:b[1][i], reverse=reverse))\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(letters):\n",
    "    word = \"\".join(letters)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to read each character in the image and convert it to text\n",
    "- Procedure of img processing need to be improved to achieve better recognition results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_read_cnt(letters, temp, contours, model, img_size):\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if w > 10 and h > 10:\n",
    "            cv2.rectangle(temp,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "            #predict letter in this rectangle\n",
    "            # plt.imshow(temp)\n",
    "            # plt.show()\n",
    "            letter = temp[y:y+h,x:x+w]\n",
    "            letter = cv2.resize(letter, (img_size, img_size))\n",
    "            letter = cv2.cvtColor(letter, cv2.COLOR_BGRA2GRAY)\n",
    "            letter = cv2.GaussianBlur(letter, (3, 3), 0)\n",
    "            ret, letter = cv2.threshold(letter, 127, 255, cv2.THRESH_BINARY, cv2.THRESH_OTSU)\n",
    "            letter = cv2.bilateralFilter(letter, 3, 100, 100, borderType=cv2.BORDER_CONSTANT)\n",
    "            # morph\n",
    "            kernel = np.ones((1,1), np.uint8)\n",
    "            letter = cv2.erode(letter, kernel, iterations=1)\n",
    "            letter = cv2.dilate(letter, kernel, iterations=1)\n",
    "            letter = cv2.bitwise_not(letter)\n",
    "                \n",
    "            letter = letter.astype(\"float32\") / 255.0\n",
    "            letter = np.expand_dims(letter, axis=2)\n",
    "            letter = np.expand_dims(letter, axis=0)\n",
    "            # plt.imshow(letter.reshape(32,32))\n",
    "            # plt.show()\n",
    "            prediction = model.predict(letter)\n",
    "            prediction = lb.inverse_transform(prediction)\n",
    "#           print(prediction)\n",
    "            letters.append(prediction[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectText (img):\n",
    "    # get predictions of text boxes\n",
    "    predictions = detector.detect(images=[img])[0]\n",
    "\n",
    "    # draw boxes around text\n",
    "    image = keras_ocr.tools.drawBoxes(img, predictions, (0,255,0), 0)\n",
    "\n",
    "    # show image\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    # process each detected box as a separate image\n",
    "    #for i in range(len(predictions)):\n",
    "    for i in range(3): #fore testing to check only first 3 words\n",
    "        letters = []\n",
    "        old_letters = []\n",
    "        temp = keras_ocr.tools.warpBox(img, predictions[i], margin=2) # crop each word\n",
    "        plt.imshow(temp)\n",
    "        plt.show()\n",
    "\n",
    "        #img processing\n",
    "        gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "        tresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "        #contours\n",
    "        contours, hierarchy = cv2.findContours(tresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        contours = sort_contours(contours, method=\"left-to-right\")[0]\n",
    "\n",
    "        #remove first contour (bounding box of entire image)\n",
    "        contours = contours[1:]\n",
    "\n",
    "        #draw bounding boxes around contours of letters from left to right and predict with models trained on different datasets\n",
    "        ocr_read_cnt(letters, temp, contours, model, 28)\n",
    "        word = get_word(letters)\n",
    "        print('printed model: ', word)\n",
    "\n",
    "        ocr_read_cnt(old_letters, temp, contours, old_model, 32)\n",
    "        word = get_word(old_letters)\n",
    "        print('handrwitten model: ', word)\n",
    "\n",
    "        # save each image (uncomment to save)\n",
    "      #  tf.keras.utils.save_img('images/temp_text_{}.jpg'.format(i), temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with an image of a product label from phone camera\n",
    "imgTest = keras_ocr.tools.read('images/product_test_2.jpg')\n",
    "detectText(imgTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
